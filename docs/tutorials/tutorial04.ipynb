{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgtY-H9A--wi"
   },
   "source": [
    "# Tutorial 04 - Optimizing Force Fields\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openforcefield/openff-evaluator/blob/main/docs/tutorials/tutorial04.ipynb)\n",
    "\n",
    "In this tutorial we will be using the OpenFF Evaluator framework in combination with the fantastic [*ForceBalance*](\n",
    "https://github.com/leeping/forcebalance) software to optimize a molecular force field against the physical property data \n",
    "set we created in the [first tutorial](tutorial01.ipynb).\n",
    "\n",
    "*ForceBalance* offers a suite of tools for optimizing molecular force fields against a set of target data. Perhaps one of \n",
    "the most fundamental targets to fit against is experimental physical property data. Physical property data has been used \n",
    "extensively for decades to inform the values of non-bonded Van der Waals (VdW) interaction parameters (often referred to \n",
    "as Lennard-Jones parameters).\n",
    "\n",
    "*ForceBalance* is seamlessly integrated with the evaluator framework, using it to evaluate the deviations between\n",
    "target experimentally measured data points and those evaluated using the force field being optimized (as well as the \n",
    "gradient of those deviations with respect to the force field parameters being optimized).\n",
    "\n",
    "The tutorial will cover:\n",
    "\n",
    "- setting up the input files and directory structure required by ForceBalace.\n",
    "- setting up an `EvaluatorServer` for *ForceBalance* to connect to.\n",
    "- running *ForceBalance* using those input files.\n",
    "- extracting and plotting a number of statistics output during the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPgYOGJG--wj"
   },
   "source": [
    "*Note: If you are running this tutorial in google colab you will need to run a setup script instead of following the \n",
    "installation instructions:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS7HuXMj--wn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/openforcefield/openff-evaluator/main/docs/tutorials/colab_setup.ipynb\n",
    "# %run colab_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JOt9Apq--wt"
   },
   "source": [
    "*For this tutorial make sure that you are using a GPU accelerated runtime.*\n",
    "\n",
    "For the sake of clarity all warnings will be disabled in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7tFiECf--wu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"openff.toolkit\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFwGxGQA--w0"
   },
   "source": [
    "We will also enable time-stamped logging to help track the progress of our calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nqp2BKbJ--w1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openff.evaluator.utils import setup_timestamp_logging\n",
    "\n",
    "setup_timestamp_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdnCJ18b--w6"
   },
   "source": [
    "## Setting up the ForceBalance Inputs\n",
    "\n",
    "In this section we will be creating the directory structure required by *ForceBalance*, and populating it with the \n",
    "required input files.\n",
    "\n",
    "### Creating the Directory Structure\n",
    "\n",
    "To begin with, we will create a directory to store the starting force field parameters in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fp-lsXMt--w7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir forcefield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7sd8tN8--w-"
   },
   "source": [
    "and one to store the input parameters for our 'fitting target' - in this case a data set of physical properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZX45ta6--xA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p targets/pure_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYYPy60I--xE"
   },
   "source": [
    "### Defining the Training Data Set\n",
    "\n",
    "With the directories created, we will next specify the data set of physical properties which we will be training the \n",
    "force field against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlLsxPQm--xG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# For convenience we will use the copy shipped with the framework\n",
    "from openff.evaluator.utils import get_data_filename\n",
    "\n",
    "data_set_path = get_data_filename(\"tutorials/tutorial01/filtered_data_set.json\")\n",
    "\n",
    "# Load the data set.\n",
    "from openff.evaluator.datasets import PhysicalPropertyDataSet\n",
    "\n",
    "data_set = PhysicalPropertyDataSet.from_json(data_set_path)\n",
    "\n",
    "# Due to a small bug in ForceBalance we need to zero out any uncertainties\n",
    "# which are undefined. This will be fixed in future versions.\n",
    "from openff.evaluator.attributes import UNDEFINED\n",
    "\n",
    "for physical_property in data_set:\n",
    "    if physical_property.uncertainty != UNDEFINED:\n",
    "        continue\n",
    "\n",
    "    physical_property.uncertainty = 0.0 * physical_property.default_unit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaPGpS4d--xL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To speed up the runtime of this tutorial, we will only train the force field against measurements made for ethanol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD7Vim_u--xM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openff.evaluator.datasets.curation.components.filtering import (\n",
    "    FilterBySmiles,\n",
    "    FilterBySmilesSchema,\n",
    ")\n",
    "\n",
    "data_set = FilterBySmiles.apply(\n",
    "    data_set,\n",
    "    FilterBySmilesSchema(smiles_to_include=[\"CCO\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDpgPpB4--xQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "in real optimizations however the data set should be **much** larger than two data points!\n",
    "\n",
    "With those changes made, we can save the data set in our targets directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMsDtL9y--xR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Store the data set in the `pure_data` targets folder:\n",
    "data_set.json(\"targets/pure_data/training_set.json\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Zy5rehy--xV"
   },
   "source": [
    "### Defining the Starting Force Field Parameters\n",
    "\n",
    "We will use the OpenFF Parsley 1.0.0 force field as the starting parameters for the optimization. These can be loaded\n",
    "directly into an OpenFF `ForceField` object using the OpenFF toolkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EaHKkQ61--xW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openff.toolkit.typing.engines.smirnoff import ForceField\n",
    "\n",
    "force_field = ForceField(\"openff-1.0.0.offxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCSYfufg--xa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to use these parameters in *ForceBalance*, we need to 'tag' the individual parameters in the force field that\n",
    "we wish to optimize. The toolkit easily enables us to add these tags using cosmetic attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fFzLhLKE--xb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the smiles of all unique components in our data set.\n",
    "from openff.toolkit.topology import Molecule, Topology\n",
    "\n",
    "all_smiles = {\n",
    "    component.smiles\n",
    "    for substance in data_set.substances\n",
    "    for component in substance.components\n",
    "}\n",
    "\n",
    "for smiles in all_smiles:\n",
    "    # Find those VdW parameters which would be applied to those components.\n",
    "    molecule = Molecule.from_smiles(smiles)\n",
    "    topology = Topology.from_molecules([molecule])\n",
    "\n",
    "    labels = force_field.label_molecules(topology)[0]\n",
    "\n",
    "    # Tag the exercised parameters as to be optimized.\n",
    "    for parameter in labels[\"vdW\"].values():\n",
    "        parameter.add_cosmetic_attribute(\"parameterize\", \"epsilon, rmin_half\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cIs15IZl--xe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we have made use of the toolkit's handy `label_molecules` function to see which VdW parameters will be assigned\n",
    "to the molecules in our data set, and tagged them to be parameterized.\n",
    "\n",
    "With those tags added, we can save the parameters in the `forcefield` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOs0bcBo--xf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the annotated force field file.\n",
    "force_field.to_file(\"forcefield/openff-1.0.0-tagged.offxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zu8JXeni--xj"
   },
   "source": [
    "*Note: The force field parameters are stored in the [OpenFF SMIRNOFF XML format](https://open-forcefield-toolkit.readthedocs.io/en/0.6.0/smirnoff.html).*\n",
    "\n",
    "### Creating the Main Input File\n",
    "\n",
    "Next, we will create the main *ForceBalance* input file. For the sake of brevity a default input file which ships with \n",
    "this framework will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OnaiZmGW--xl",
    "outputId": "bffbe59b-b819-4307-d5fd-4f01fd2422e6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_file_path = get_data_filename(\"tutorials/tutorial04/optimize.in\")\n",
    "\n",
    "# Copy the input file into our directory structure\n",
    "import shutil\n",
    "\n",
    "shutil.copyfile(input_file_path, \"optimize.in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oxvx-yIo--xq"
   },
   "source": [
    "While there are many options that can be set within this file, the main options of interest for our purposes appear\n",
    "at the bottom of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "vDgpFQUq--xr",
    "outputId": "bc95c1d2-991b-422d-e503-2b68fdd5e250",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!tail -n 6 optimize.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SleJoA3i--xu"
   },
   "source": [
    "Here we have specified that we wish to create a new *ForceBalance* `Evaluator_SMIRNOFF` target called `pure_data` \n",
    "(corresponding to the name of the directory we created in the earlier step).\n",
    " \n",
    "The main input to this target is the file path to an `options.json` file - it is this file which will specify all the\n",
    "options which should be used when *ForceBalance* requests that our target data set be estimated using the current sets\n",
    "of force field parameters.\n",
    "\n",
    "We will create this file in the `targets/pure_data` directory later in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DIUi886c--xv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data set is the JSON serialized representation of the `PhysicalPropertyDataSet` we created during the [first \n",
    "tutorial](tutorial01.ipynb).\n",
    "\n",
    "### Defining the Estimation Options\n",
    "\n",
    "The final step before we can start the optimization is to create the set of options which will govern how our data set\n",
    "is estimated using the Evaluator framework.\n",
    " \n",
    "These options will be stored in an `Evaluator_SMIRNOFF` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tyloz19F--xw",
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "from forcebalance.evaluator_io import Evaluator_SMIRNOFF\n",
    "\n",
    "# Create the ForceBalance options object\n",
    "target_options = Evaluator_SMIRNOFF.OptionsFile()\n",
    "# Set the path to the data set\n",
    "target_options.data_set_path = \"training_set.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOy6-hgf--xz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This object exposes both a set of *ForceBalance* specific options, as well as the set of Evaluator options. \n",
    "\n",
    "The *ForceBalance* specific options allow us to define how each type of property will contribute to the optimization\n",
    "objective function (the value which we are trying to minimize):\n",
    "\n",
    "$$\\Delta(\\theta) = \\sum^N_n \\dfrac{weight_n}{M_n} \\sum^{M_n}_m \\left(\\dfrac{y_m^{ref} - y_m(\\theta)}{denominator_{n}}\\right)^2$$ \n",
    "\n",
    "where $N$ is the number of types of properties (e.g. density, enthalpy of vaporization, etc.), $M_n$ is the number of\n",
    "data points of type $n$, $y_m^{ref}$ is the experimental value of data point $m$ and $y_m(\\theta)$ is the estimated \n",
    "value of data point $m$ using the current force field parameters\n",
    "\n",
    "In particular, the options object allows us to specify both an amount to scale each type of properties contribution to \n",
    "the objective function by ($weight_n$), and the amount to scale the difference between the experimental and estimated\n",
    "properties ($denominator_n$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLM9plwn--xz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openff.units import unit\n",
    "\n",
    "target_options.weights = {\"Density\": 1.0, \"EnthalpyOfVaporization\": 1.0}\n",
    "target_options.denominators = {\n",
    "    \"Density\": 30.0 * unit.kilogram / unit.meter**3,\n",
    "    \"EnthalpyOfVaporization\": 3.0 * unit.kilojoule / unit.mole,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfdFCewd--x3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " \n",
    "where here we have chosen values that ensure that both types of properties contribute roughly equally to the total\n",
    "objective function.\n",
    "\n",
    "The Evaluator specific options correspond to a standard `RequestOptions` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70fNiyjg--x4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openff.evaluator.client import RequestOptions\n",
    "\n",
    "# Create the options which evaluator should use.\n",
    "evaluator_options = RequestOptions()\n",
    "# Choose which calculation layers to make available.\n",
    "evaluator_options.calculation_layers = [\"SimulationLayer\"]\n",
    "\n",
    "# Reduce the default number of molecules\n",
    "from openff.evaluator.properties import Density, EnthalpyOfVaporization\n",
    "\n",
    "density_schema = Density.default_simulation_schema(n_molecules=256)\n",
    "h_vap_schema = EnthalpyOfVaporization.default_simulation_schema(n_molecules=256)\n",
    "\n",
    "evaluator_options.add_schema(\"SimulationLayer\", \"Density\", density_schema)\n",
    "evaluator_options.add_schema(\"SimulationLayer\", \"EnthalpyOfVaporization\", h_vap_schema)\n",
    "\n",
    "target_options.estimation_options = evaluator_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O4-QdP-E--x7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These options allow us to control exactly how each type of property should be estimated, which calculation approaches\n",
    "should be used and more. Here we use the same options are were used in the [second tutorial](tutorial02.ipynb)\n",
    "\n",
    "*Note: more information about the different estimation options can be [found here](../gettingstarted/client.rst)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qXKzNY7--x8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And that's the options created! We will finish off by serializing the options into our target directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TNFFE75--x9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the options to file.\n",
    "with open(\"targets/pure_data/options.json\", \"w\") as file:\n",
    "    file.write(target_options.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZkeoQTV--yA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Launching an Evaluator Server\n",
    "\n",
    "With the *ForceBalance* options created, we can now move onto launching the `EvaluatorServer` which *ForceBalance* will \n",
    "call out to when it needs the data set to be evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jdr55Aez--yA",
    "outputId": "b56f258e-55c3-4e21-ae0c-fb939c37a95e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Launch the calculation backend which will distribute any calculations.\n",
    "from openff.evaluator.backends import ComputeResources\n",
    "from openff.evaluator.backends.dask import DaskLocalCluster\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "calculation_backend = DaskLocalCluster(\n",
    "    number_of_workers=1,\n",
    "    resources_per_worker=ComputeResources(\n",
    "        number_of_threads=1,\n",
    "        number_of_gpus=1,\n",
    "        preferred_gpu_toolkit=ComputeResources.GPUToolkit.CUDA,\n",
    "    ),\n",
    ")\n",
    "calculation_backend.start()\n",
    "\n",
    "# Launch the server object which will listen for estimation requests and schedule any\n",
    "# required calculations.\n",
    "from openff.evaluator.server import EvaluatorServer\n",
    "\n",
    "evaluator_server = EvaluatorServer(calculation_backend=calculation_backend)\n",
    "evaluator_server.start(asynchronous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2QFxF68--yF"
   },
   "source": [
    "We will not go into the details of this here as this was already covered in the [second tutorial](tutorial02.ipynb)\n",
    "\n",
    "## Running ForceBalance\n",
    "\n",
    "With the inputs created and an Evaluator server spun up, we are finally ready to run the optimization! This can be \n",
    "accomplished with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKt1jGxI--yG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ForceBalance optimize.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSuicGKR--yI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If everything went well *ForceBalance* should exit cleanly, and will have stored out newly optimized force field in the\n",
    "`results` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9XwxXlBX--yK",
    "outputId": "c0640494-9b26-4f7e-8e79-406158c3ab3d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls result/optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THb-Zxd4--yN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting the results\n",
    "\n",
    "As a last step in this tutorial, we will extract the objective function at each iteration from the *ForceBalance* output\n",
    "files and plot this using `matplotlib`.\n",
    "\n",
    "First, we will extract the objective function from the `pickle` serialized output files which can be found in the \n",
    "`optimize.tmp/pure_data/iter_****/` directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o5Hhm6XB--yP",
    "outputId": "8fc45775-b549-425f-f49e-2e0c8fec1b78",
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "# Determine how many iterations ForceBalance has completed.\n",
    "from glob import glob\n",
    "\n",
    "from forcebalance.nifty import lp_load\n",
    "\n",
    "n_iterations = len(glob(\"optimize.tmp/pure_data/iter*\"))\n",
    "\n",
    "# Extract the objective function at each iteration.\n",
    "objective_function = []\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    folder_name = \"iter_\" + str(iteration).zfill(4)\n",
    "    file_path = f\"optimize.tmp/pure_data/{folder_name}/objective.p\"\n",
    "\n",
    "    statistics = lp_load(file_path)\n",
    "    objective_function.append(statistics[\"X\"])\n",
    "\n",
    "print(objective_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0VXrv-3--yT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The objective function is then easily plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "DzOieX2B--yU",
    "outputId": "51331014-27cc-4829-84b6-bf64f0a550f4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "figure, axis = pyplot.subplots(1, 1, figsize=(4, 4))\n",
    "\n",
    "axis.set_xlabel(\"Iteration\")\n",
    "axis.set_ylabel(\"Objective Function\")\n",
    "\n",
    "axis.plot(range(n_iterations), objective_function, marker=\"o\")\n",
    "\n",
    "figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbzleU137H9m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "And that concludes the fourth tutorial! \n",
    "\n",
    "If you have any questions and / or feedback, please open an issue on the\n",
    "[GitHub issue tracker](https://github.com/openforcefield/openff-evaluator/issues)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial04.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/openforcefield/openff-evaluator/blob/main/docs/tutorials/tutorial04.ipynb",
     "timestamp": 1583264626727
    }
   ]
  },
  "kernelspec": {
   "display_name": "evaluator-test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "410f84a7dee2fd8da3e676bc69193e1fbd008e9a63ed8da16ae0332e91fd8194"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
